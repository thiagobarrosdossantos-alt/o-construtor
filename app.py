import streamlit as st
import os
from dotenv import load_dotenv
from google import genai # Biblioteca nova do Google (SDK v2)

# --- 1. CONFIGURA√á√ÉO DA P√ÅGINA ---
st.set_page_config(
    page_title="O Construtor",
    page_icon="üèóÔ∏è",
    layout="wide"
)

# Carrega as senhas do arquivo .env
load_dotenv()

# --- 2. CONFIGURA√á√ÉO DA IA (GOOGLE) ---
api_key = os.getenv("GOOGLE_API_KEY")

if not api_key:
    st.error("üö® ERRO CR√çTICO: Chave GOOGLE_API_KEY n√£o encontrada no arquivo .env")
    st.info("Crie um arquivo .env na raiz e cole sua chave: GOOGLE_API_KEY=AIza...")
    st.stop()

# Inicializa o cliente com a biblioteca nova
try:
    client = genai.Client(api_key=api_key)
except Exception as e:
    st.error(f"Erro ao inicializar o cliente Google: {e}")
    st.stop()

# --- 3. ESCOLHA DO MODELO ---
# DICA: Se o 'gemini-3-pro-preview' der erro, troque por 'gemini-2.0-flash-exp'
MODELO_ATUAL = "gemini-2.0-flash-exp" 

# --- 4. INTERFACE VISUAL ---
st.title("üèóÔ∏è O Construtor")
st.caption(f"Sistema Aut√¥nomo de Engenharia de Software | Motor: {MODELO_ATUAL}")

# Bot√£o na barra lateral para limpar mem√≥ria
if st.sidebar.button("üóëÔ∏è Limpar Conversa"):
    st.session_state.messages = []
    st.rerun()

# --- 5. GERENCIAMENTO DE ESTADO (MEM√ìRIA) ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# Mostra o hist√≥rico de mensagens na tela
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- 6. L√ìGICA DO CHAT ---
if prompt := st.chat_input("D√™ uma ordem para a constru√ß√£o..."):
    # 1. Mostra a mensagem do usu√°rio
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # 2. Gera a resposta da IA
    with st.chat_message("assistant"):
        placeholder = st.empty()
        placeholder.markdown("‚è≥ *O Construtor est√° pensando...*")
        
        try:
            # Chamada para a API nova do Google
            response = client.models.generate_content(
                model=MODELO_ATUAL,
                contents=prompt
            )
            
            texto_resposta = response.text
            placeholder.markdown(texto_resposta)
            
            # 3. Salva no hist√≥rico
            st.session_state.messages.append({"role": "assistant", "content": texto_resposta})
            
        except Exception as e:
            placeholder.error(f"‚ùå Erro no processamento: {e}")